{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "result = load_dotenv(find_dotenv()) # \n",
    "\n",
    "#os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv(\"_LANGCHAIN_TRACING_V2\")\n",
    "#os.environ[\"LANGCHAIN_ENDPOINT\"] = os.getenv(\"_LANGCHAIN_ENDPOINT\")\n",
    "#os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"_LANGCHAIN_API_KEY\")\n",
    "#os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"_LANGCHAIN_PROJECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5_/w60z7jfd3kggxf5884bbg2ym0000gn/T/ipykernel_48855/2324389574.py:13: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(llm=llm)\n",
      "/Users/gianmariaricci/develop/github/ai-playground/src/python/various/various/lib/python3.12/site-packages/pydantic/main.py:212: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai  import AzureChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "\ttemperature=0,\n",
    "    openai_api_version=\"2023-09-01-preview\",\n",
    "    deployment_name=\"GPT-4o-mini\", #Deployment name\n",
    "    azure_endpoint=os.environ[\"OPENAI_API_BASE\"],\n",
    "    model_name=\"GPT-4o-mini\"\n",
    ")\n",
    "\n",
    "# now initialize the conversation chain\n",
    "conversation = ConversationChain(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.memory.buffer.ConversationBufferMemory'>\n"
     ]
    }
   ],
   "source": [
    "print(type(conversation.memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from pprint import pprint\n",
    "def invoke_conversation(conversation, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = conversation.invoke({\"input\": query})\n",
    "        pprint(f'Spent a total of {cb.total_tokens} tokens with cost ${cb.total_cost:.8f}')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Spent a total of 97 tokens with cost $0.00002535'\n",
      "{'history': '',\n",
      " 'input': 'Good morning AI my name is Gianmaria!',\n",
      " 'response': \"Good morning, Gianmaria! It's great to meet you! How's your day \"\n",
      "             'starting off? Anything exciting planned?'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "conversation.memory.clear()\n",
    "response = invoke_conversation(conversation, \"Good morning AI my name is Gianmaria!\")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Good morning AI my name is Gianmaria!\n",
      "AI: Good morning, Gianmaria! It's great to meet you! How's your day starting off? Anything exciting planned?\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Spent a total of 138 tokens with cost $0.00003510'\n",
      "{'history': 'Human: Good morning AI my name is Gianmaria!\\n'\n",
      "            \"AI: Good morning, Gianmaria! It's great to meet you! How's your \"\n",
      "            'day starting off? Anything exciting planned?',\n",
      " 'input': 'What is my name?',\n",
      " 'response': \"Your name is Gianmaria! It's a lovely name. Do you have any \"\n",
      "             'special meaning behind it, or is there a story to how you got '\n",
      "             'it?'}\n"
     ]
    }
   ],
   "source": [
    "response = invoke_conversation(conversation, \"What is my name?\")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Good morning AI my name is Gianmaria!\n",
      "AI: Good morning, Gianmaria! It's great to meet you! How's your day starting off? Anything exciting planned?\n",
      "Human: What is my name?\n",
      "AI: Your name is Gianmaria! It's a lovely name. Do you have any special meaning behind it, or is there a story to how you got it?\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Spent a total of 207 tokens with cost $0.00005715'\n",
      "{'history': 'Human: Good morning AI my name is Gianmaria!\\n'\n",
      "            \"AI: Good morning, Gianmaria! It's great to meet you! How's your \"\n",
      "            'day starting off? Anything exciting planned?\\n'\n",
      "            'Human: What is my name?\\n'\n",
      "            \"AI: Your name is Gianmaria! It's a lovely name. Do you have any \"\n",
      "            'special meaning behind it, or is there a story to how you got it?',\n",
      " 'input': 'What is the capital of italy?',\n",
      " 'response': \"The capital of Italy is Rome! It's a city rich in history, known \"\n",
      "             'for its ancient ruins like the Colosseum and the Roman Forum, as '\n",
      "             'well as its stunning architecture, delicious cuisine, and '\n",
      "             'vibrant culture. Have you ever been to Rome, or is it on your '\n",
      "             'travel list?'}\n"
     ]
    }
   ],
   "source": [
    "response = invoke_conversation(conversation, \"What is the capital of italy?\")\n",
    "pprint(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Spent a total of 301 tokens with cost $0.00006945'\n",
      "(\"Good morning, Gianmaria! It's great to meet you! How's your day starting \"\n",
      " 'off? Anything exciting planned?')\n",
      "The human introduces himself as Gianmaria. The AI greets him warmly and asks how his day is starting and if he has any exciting plans.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
    "\n",
    "summary_buffer_memory = ConversationSummaryMemory(llm=llm, max_token_limit=40)\n",
    "\n",
    "conversation_sum = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=summary_buffer_memory\n",
    ")\n",
    "\n",
    "response = invoke_conversation(conversation_sum, \"Good morning AI my name is Gianmaria!\")\n",
    "pprint(response[\"response\"])\n",
    "print(summary_buffer_memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human introduces himself as Gianmaria. The AI greets him warmly and asks how his day is starting and if he has any exciting plans.\n"
     ]
    }
   ],
   "source": [
    "print (conversation_sum.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Spent a total of 1225 tokens with cost $0.00037365'\n",
      "('The Hertzsprung-Russell diagram is a fascinating tool used in astronomy to '\n",
      " 'classify stars based on their luminosity (brightness) and surface '\n",
      " 'temperature. It essentially plots stars on a graph where the x-axis '\n",
      " 'represents the surface temperature (decreasing from left to right) and the '\n",
      " 'y-axis represents luminosity (increasing from bottom to top).\\n'\n",
      " '\\n'\n",
      " \"In this diagram, you'll find several distinct regions:\\n\"\n",
      " '\\n'\n",
      " '1. **Main Sequence**: This is where most stars, including our Sun, are '\n",
      " 'located. Stars in this region fuse hydrogen into helium in their cores. The '\n",
      " 'Sun is classified as a G-type main-sequence star (G dwarf), with a surface '\n",
      " 'temperature of about 5,500 degrees Celsius and a luminosity of one solar '\n",
      " 'unit.\\n'\n",
      " '\\n'\n",
      " '2. **Giants**: These stars are larger and more luminous than main-sequence '\n",
      " 'stars and are found above the main sequence on the diagram.\\n'\n",
      " '\\n'\n",
      " '3. **Supergiants**: These are even more massive and luminous than giants, '\n",
      " 'located at the top of the diagram.\\n'\n",
      " '\\n'\n",
      " '4. **White Dwarfs**: These are the remnants of stars that have exhausted '\n",
      " 'their nuclear fuel, found in the lower left part of the diagram.\\n'\n",
      " '\\n'\n",
      " 'The Sun, being a G-type main-sequence star, is in the middle of the main '\n",
      " 'sequence, which is where stars spend the majority of their lifetimes. If you '\n",
      " 'have more questions about stars or anything else, feel free to ask!')\n"
     ]
    }
   ],
   "source": [
    "response = invoke_conversation(conversation_sum, \"explain hersprung russel diagram and tell me the type of our sun?\")\n",
    "pprint(response[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The human introduces himself as Gianmaria. The AI greets him warmly and '\n",
      " 'inquires about his day and plans. Gianmaria asks the AI to explain the '\n",
      " 'Hertzsprung-Russell diagram and the type of star our Sun is. The AI explains '\n",
      " 'that the Hertzsprung-Russell diagram categorizes stars by luminosity and '\n",
      " 'surface temperature, detailing regions such as the main sequence, giants, '\n",
      " 'supergiants, and white dwarfs. It notes that the Sun is a G-type '\n",
      " 'main-sequence star with a surface temperature of about 5,500 degrees Celsius '\n",
      " 'and a luminosity of one solar unit, and invites Gianmaria to ask more '\n",
      " 'questions if he has any.')\n"
     ]
    }
   ],
   "source": [
    "pprint(conversation_sum.memory.buffer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "various",
   "language": "python",
   "name": "various"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
